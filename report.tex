\documentclass[10pt,a4paper,twocolumn]{article}
\usepackage{amssymb,amsmath}
\usepackage{graphicx} 	 
\usepackage{times}
\title{IVR First Assignment}
\author{Clemens Wolff, Toms Bergmanis}
\date{February 28th, 2013}

\begin{document}

\maketitle
\section{Introduction}
This report describes the work done for the first assignment in the IVR course. It gives the
aims and hypotheses that guided the work; describes the algorithms that were implemented
and reports the results of experiments that were run.

The goal of this assignment was to develop three algorithms: one that detects the robots in each image, one that correctly identifies the direction of the robot and one that links together detections of the robots in consecutive images. 

Several simplifying assumptions were made about the possible set-ups of the assignment.  Firstly, it was assumed that colours of the robots may change only due to the light it is exposed to, thus giving a rise to an assumption that robots will each appear in various shades of red or blue or green. Secondly, it was assumed that camera will be set up in some reasonable angle with respect to the plane it is supposed to observe. Finally, due to colour dependant approach it was assumed that background of the image will be in colour other than any of the colours of the robots.

\section{Methods}
In the following sections the three algorithms are described in detail. 

\subsection{Detection of Robots}

\subsection{Detection of Directions}
\begin{enumerate}
\item After having detected robot as a set of points in the image a convex hull of these points was calculated.
\textit{Further detection of the direction of the robot was done under the assumption that colour representing the robot is different and appears differently than that of the triangle indicating it's direction. Furthermore - it was assumed that the triangle will have lesser pixel colour value in the channel representing robot's colour (red or green, or blue) in RGB representation than the average pixel of the convex hull. These assumptions can be justified by the fact that area of the triangle indicating the direction of the robot constituted relatively smaller area of the convex hull than the rest of the convex hull which was expected to appear in some other colour than black. }[pics of what is what would be nice]
\item The average pixel value of the characteristic  channel was computed. Pixels which were above that value were assigned to one mask, others were omitted. 
\textit{This step gives thither and less noisy set of pixels that represent robot's coloured part.}[pics of what is what would be nice]
\item A convex hull was computed for the result of the previous step. 
\item Once more the average pixel value of the characteristic channel was computed. This time pixels which were above that value were assigned to one mask, others were assigned to another mask which was expected to represent the triangle part of the robot's image. 
\item \textbf{here is one step I might have to include or exclude depending on one expreiment I will run} 
\item Centres of both masks from the previous step were computed. 
\item Then a line joining them was drawn which depending on how precisely robot was detected would correspond to the direction of the robot.
\end{enumerate} 
[pics of what is what would be nice]

\subsection{Tracking of Robots}
After having detected the robots information about them was kept in separate arrays which were populated during the course of processing the data set. Each array consisted of  the detected coordinates of the centre of the expected mass of pixels  representing a robot  in each image. After collecting coordinates of  all robots for all frames they were plotted on a background generated by median filter algorithm. Coordinates were plotted as a five pixel large + signs of the colour of the robot they were representing. Such markers of positions of the robots then were linked together with white lines in order of the appearance of the images they originated from. 
\section{Results}
This section describes and illustrates the results of the three algorithms implemented. 
\subsection{Detection of Robots}
Detection of the robots was working perfectly on the two data sets provided, however it's performance was lower on some of the test sets with significantly different lightning conditions such as daylight or direct sun light on which error rate in some cases grow up to 10 percent of the robot instances being  undetected.  %this is kinda true casue whe have 2 test sets each having 3 robots per image with 100 images each thus about 62 out of 300 is 10 % This section should be expanded. 
\subsection{Detection of Directions}
Performance of detection of the directions was heavily dependent on the performance of the detection of the robots. In case of precisely detected robot detected direction perfectly matched the actual direction. \textbf{ilustrations}
In case of loose detection - detection where some addition non-robot region is misleadingly detected as a robot - detected direction perfectly matched the actual direction due to algorithms ability to filter noisy detections. \textbf{ilustrations} 
In case of under-detection - detection where some parts of the image representing the robot where omitted - detected direction was skewed on the side opposite (from the axis matching the actual robot's direction) to the misdirected fragment of the robot. Error was proportional to the error of under-detected area of the robot. 
\textbf{ilustrations}
\subsection{Tracking of the robots}
\section{Discussion}
Assess the success of your program with regard to the reported results, and explain any limitations, problems or improvements you would make.
\section{Code}
the new Matlab code that you developed for this assignment. Do not
include code that you downloaded from the course web pages. Any other code
that you downloaded should be recorded in the report, but does not need to
be included in the appendix.

\end{document}
